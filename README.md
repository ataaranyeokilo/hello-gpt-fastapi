# hello-gpt-fastapi


## ğŸ“Œ Project Goal
This project is a **lightweight LLM application** that demonstrates how to connect a FastAPI service to the **Azure OpenAI API**.  
The goal is to build a simple, production-ready foundation for more advanced GenAI systems such as **RAG chatbots, agentic AI workflows, and knowledge assistants**.

---

## ğŸ¯ Objectives
- Set up a clean Python environment for AI engineering projects.
- Create a FastAPI service with a `/health` and `/ask` endpoint.
- Connect the service to Azure OpenAI (GPT model).
- Deploy the service locally and later to Azure App Service.
- Establish a foundation that will be extended in later weeks (RAG, GraphRAG, agents).

---

## ğŸ› ï¸ Tech Stack
- **Python 3.9+**
- **FastAPI** â€” API framework
- **Uvicorn** â€” ASGI server
- **Azure OpenAI API** â€” LLM provider
- **python-dotenv** â€” environment variable management
- **requests** â€” for HTTP requests & testing

---

## âš™ï¸ How It Works
1. User sends a query to the `/ask` endpoint.  
2. FastAPI forwards the query to Azure OpenAI.  
3. Azure OpenAI processes the input and generates a response.  
4. FastAPI returns the answer as JSON to the user.  

---


# hello-got-fastapi
# hello-gpt-fastapi
